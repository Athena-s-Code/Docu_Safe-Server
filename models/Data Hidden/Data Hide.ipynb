{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ashfak\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pytesseract\n",
    "\n",
    "#%pip install pdfplumber\n",
    "\n",
    "import pdfplumber\n",
    "import torch\n",
    "\n",
    "#%pip install transformers\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "model_path = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_path)\n",
    "\n",
    "# Define paths to your PDF and image directories\n",
    "pdf_directory = 'D:/Projects/Project Dataset/data hygeine data/pdf'\n",
    "image_directory = 'D:/Projects/Project Dataset/CNH_Aberta'\n",
    "\n",
    "data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error while processing 1124.pdf: No /Root object! - Is this really a PDF?\n",
      "Error while processing 1648.pdf: No /Root object! - Is this really a PDF?\n",
      "Error while processing 3012.pdf: Unexpected EOF\n",
      "Error while processing 3013.pdf: Unexpected EOF\n"
     ]
    }
   ],
   "source": [
    "# Process PDF files\n",
    "for pdf_file in os.listdir(pdf_directory):\n",
    "    if pdf_file.endswith(\".pdf\"):\n",
    "        pdf_path = os.path.join(pdf_directory, pdf_file)\n",
    "        try:\n",
    "            with pdfplumber.open(pdf_path) as pdf:\n",
    "                text = ''\n",
    "                for page in pdf.pages:\n",
    "                    text += page.extract_text()\n",
    "                data.append({\"text\": text})\n",
    "        except Exception as e:\n",
    "            print(f\"Error while processing {pdf_file}: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing 00000000_gt_segmentation.jpg: name 'Image' is not defined\n",
      "Error processing 00000000_in - Copy.jpg: name 'Image' is not defined\n",
      "Error processing 00000000_in.jpg: name 'Image' is not defined\n",
      "Error processing 00000001_gt_segmentation.jpg: name 'Image' is not defined\n",
      "Error processing 00000001_in - Copy.jpg: name 'Image' is not defined\n",
      "Error processing 00000001_in.jpg: name 'Image' is not defined\n",
      "Error processing 00000002_gt_segmentation.jpg: name 'Image' is not defined\n",
      "Error processing 00000002_in.jpg: name 'Image' is not defined\n",
      "Error processing 00000003_gt_segmentation.jpg: name 'Image' is not defined\n",
      "Error processing 00000003_in.jpg: name 'Image' is not defined\n",
      "Error processing 00000004_gt_segmentation.jpg: name 'Image' is not defined\n",
      "Error processing 00000004_in.jpg: name 'Image' is not defined\n",
      "Error processing 00000005_gt_segmentation.jpg: name 'Image' is not defined\n",
      "Error processing 00000005_in.jpg: name 'Image' is not defined\n",
      "Error processing 00000006_gt_segmentation.jpg: name 'Image' is not defined\n",
      "Error processing 00000006_in.jpg: name 'Image' is not defined\n",
      "Error processing 00000007_gt_segmentation.jpg: name 'Image' is not defined\n",
      "Error processing 00000007_in.jpg: name 'Image' is not defined\n",
      "Error processing 00000008_gt_segmentation.jpg: name 'Image' is not defined\n",
      "Error processing 00000008_in.jpg: name 'Image' is not defined\n",
      "Error processing 00000009_gt_segmentation.jpg: name 'Image' is not defined\n",
      "Error processing 00000009_in.jpg: name 'Image' is not defined\n",
      "Error processing 00000010_gt_segmentation.jpg: name 'Image' is not defined\n",
      "Error processing 00000010_in.jpg: name 'Image' is not defined\n",
      "Error processing 00000011_gt_segmentation.jpg: name 'Image' is not defined\n",
      "Error processing 00000011_in.jpg: name 'Image' is not defined\n",
      "Error processing 00000012_gt_segmentation.jpg: name 'Image' is not defined\n",
      "Error processing 00000012_in.jpg: name 'Image' is not defined\n",
      "Error processing 00000013_gt_segmentation.jpg: name 'Image' is not defined\n",
      "Error processing 00000013_in.jpg: name 'Image' is not defined\n",
      "Error processing 00000014_gt_segmentation.jpg: name 'Image' is not defined\n",
      "Error processing 00000014_in.jpg: name 'Image' is not defined\n",
      "Error processing 00000015_gt_segmentation.jpg: name 'Image' is not defined\n",
      "Error processing 00000015_in.jpg: name 'Image' is not defined\n",
      "Error processing 00000016_gt_segmentation.jpg: name 'Image' is not defined\n",
      "Error processing 00000016_in.jpg: name 'Image' is not defined\n",
      "Error processing 00000017_gt_segmentation.jpg: name 'Image' is not defined\n",
      "Error processing 00000017_in.jpg: name 'Image' is not defined\n",
      "Error processing 00000018_gt_segmentation.jpg: name 'Image' is not defined\n",
      "Error processing 00000018_in.jpg: name 'Image' is not defined\n",
      "Error processing 00000019_gt_segmentation.jpg: name 'Image' is not defined\n",
      "Error processing 00000019_in.jpg: name 'Image' is not defined\n",
      "Error processing 00000020_gt_segmentation.jpg: name 'Image' is not defined\n",
      "Error processing 00000020_in.jpg: name 'Image' is not defined\n",
      "Error processing 00000021_gt_segmentation.jpg: name 'Image' is not defined\n",
      "Error processing 00000021_in.jpg: name 'Image' is not defined\n",
      "Error processing 00000022_gt_segmentation.jpg: name 'Image' is not defined\n",
      "Error processing 00000022_in.jpg: name 'Image' is not defined\n",
      "Error processing 00000023_gt_segmentation.jpg: name 'Image' is not defined\n",
      "Error processing 00000023_in.jpg: name 'Image' is not defined\n",
      "Error processing 00000024_gt_segmentation.jpg: name 'Image' is not defined\n",
      "Error processing 00000024_in.jpg: name 'Image' is not defined\n",
      "Error processing 00000025_gt_segmentation.jpg: name 'Image' is not defined\n",
      "Error processing 00000025_in.jpg: name 'Image' is not defined\n",
      "Error processing 00000026_gt_segmentation.jpg: name 'Image' is not defined\n",
      "Error processing 00000026_in.jpg: name 'Image' is not defined\n",
      "Error processing 00000027_gt_segmentation.jpg: name 'Image' is not defined\n",
      "Error processing 00000027_in.jpg: name 'Image' is not defined\n",
      "Error processing 00000028_gt_segmentation.jpg: name 'Image' is not defined\n",
      "Error processing 00000028_in.jpg: name 'Image' is not defined\n",
      "Error processing 00000029_gt_segmentation.jpg: name 'Image' is not defined\n",
      "Error processing 00000029_in.jpg: name 'Image' is not defined\n",
      "Error processing 00000030_gt_segmentation.jpg: name 'Image' is not defined\n",
      "Error processing 00000030_in.jpg: name 'Image' is not defined\n",
      "Error processing 00000031_gt_segmentation.jpg: name 'Image' is not defined\n",
      "Error processing 00000031_in.jpg: name 'Image' is not defined\n",
      "Error processing 00000032_gt_segmentation.jpg: name 'Image' is not defined\n",
      "Error processing 00000032_in.jpg: name 'Image' is not defined\n",
      "Error processing 00000033_gt_segmentation.jpg: name 'Image' is not defined\n",
      "Error processing 00000033_in.jpg: name 'Image' is not defined\n"
     ]
    }
   ],
   "source": [
    "# Process image files\n",
    "for image_file in os.listdir(image_directory):\n",
    "    if image_file.endswith((\".jpg\", \".png\")):\n",
    "        image_path = os.path.join(image_directory, image_file)\n",
    "        try:\n",
    "            image = Image.open(image_path)\n",
    "            text = pytesseract.image_to_string(image)\n",
    "            data.append({\"text\": text})\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {image_file}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from transformers import BertTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define model parameters\n",
    "vocab_size = tokenizer.vocab_size\n",
    "embedding_dim = 128\n",
    "hidden_dim = 256\n",
    "learning_rate = 0.001\n",
    "batch_size = 32\n",
    "epochs = 1\n",
    "\n",
    "# Define your RedactionModel\n",
    "class RedactionModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim):\n",
    "        super(RedactionModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.decoder = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.output_layer = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, decoder_hidden=None):\n",
    "        embedded_decoder_input = self.embedding(input_ids[:, :-1])\n",
    "        if decoder_hidden is None:\n",
    "            batch_size = input_ids.size(0)\n",
    "            decoder_hidden = (\n",
    "                torch.zeros(1, batch_size, self.decoder.hidden_size).to(input_ids.device),\n",
    "                torch.zeros(1, batch_size, self.decoder.hidden_size).to(input_ids.device)\n",
    "            )\n",
    "        decoder_output, _ = self.decoder(embedded_decoder_input, decoder_hidden)\n",
    "        output = self.output_layer(decoder_output)\n",
    "        return output\n",
    "\n",
    "# Create the model, loss function, and optimizer\n",
    "model = RedactionModel(vocab_size, embedding_dim, hidden_dim)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize and encode the data\n",
    "input_ids = []\n",
    "attention_mask = []\n",
    "\n",
    "max_length = 128 \n",
    "\n",
    "for entry in data:\n",
    "    encoding = tokenizer(entry['text'], padding='max_length', truncation=True, max_length=max_length, return_tensors='pt')\n",
    "    input_ids.append(encoding['input_ids'][0])  # Extract the tensor from the list\n",
    "    attention_mask.append(encoding['attention_mask'][0])  # Extract the tensor from the list\n",
    "\n",
    "input_ids = torch.stack(input_ids)\n",
    "attention_mask = torch.stack(attention_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and validation sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_input_ids, val_input_ids, train_attention_mask, val_attention_mask = train_test_split(\n",
    "    input_ids, attention_mask, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Create DataLoader for training\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "train_dataset = TensorDataset(train_input_ids, train_attention_mask)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Average Loss: 6.9261\n",
      "Epoch [2/10], Average Loss: 5.6258\n",
      "Epoch [3/10], Average Loss: 4.9967\n",
      "Epoch [4/10], Average Loss: 4.5927\n",
      "Epoch [5/10], Average Loss: 4.2907\n",
      "Epoch [6/10], Average Loss: 4.0463\n",
      "Epoch [7/10], Average Loss: 3.8430\n",
      "Epoch [8/10], Average Loss: 3.6650\n",
      "Epoch [9/10], Average Loss: 3.5075\n",
      "Epoch [10/10], Average Loss: 3.3671\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch_input_ids, batch_attention_mask in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_input_ids, batch_attention_mask)\n",
    "        \n",
    "        target_ids = batch_input_ids[:, 1:].clone()\n",
    "        loss = criterion(outputs.transpose(1, 2), target_ids)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    average_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Average Loss: {average_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'redaction_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RedactionModel(\n",
       "  (embedding): Embedding(30522, 128)\n",
       "  (decoder): LSTM(128, 256, batch_first=True)\n",
       "  (output_layer): Linear(in_features=256, out_features=30522, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RedactionModel(vocab_size, embedding_dim, hidden_dim)\n",
    "model.load_state_dict(torch.load('redaction_model.pth'))\n",
    "model.eval()  # Set the model to evaluation mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "\n",
    "file_path = 'D:/Projects/Project Dataset/data hygeine data/pdf/1.pdf'\n",
    "with pdfplumber.open(file_path) as pdf:\n",
    "    text = ''\n",
    "    for page in pdf.pages:\n",
    "        text += page.extract_text()\n",
    "\n",
    "# Tokenize and preprocess the text\n",
    "encoding = tokenizer(text, padding='max_length', truncation=True, max_length=max_length, return_tensors='pt')\n",
    "input_ids = encoding['input_ids']\n",
    "attention_mask = encoding['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    redacted_output = model(input_ids, attention_mask)\n",
    "    redacted_tokens = torch.argmax(redacted_output, dim=-1)\n",
    "    redacted_text = tokenizer.decode(redacted_tokens[0], skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Redacted Text:\n",
      "curriculum vitae, - -,,, -.,. -...... com.......... com. com.........................................................................................,...\n"
     ]
    }
   ],
   "source": [
    "print(\"Redacted Text:\")\n",
    "print(redacted_text)\n",
    "\n",
    "# Or save the redacted text to a file\n",
    "with open('redacted_output.txt', 'w') as f:\n",
    "    f.write(redacted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# Load text from PDF or image file\n",
    "def load_text_from_file(file_path):\n",
    "    if file_path.endswith(\".pdf\"):\n",
    "        with pdfplumber.open(file_path) as pdf:\n",
    "            text = \"\"\n",
    "            for page in pdf.pages:\n",
    "                text += page.extract_text()\n",
    "    elif file_path.endswith((\".jpg\", \".jpeg\", \".png\", \".bmp\")):\n",
    "        image = Image.open(file_path)\n",
    "        text = pytesseract.image_to_string(image)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file format\")\n",
    "    return text\n",
    "\n",
    "# Replace redacted portions with placeholders\n",
    "redacted_tokens = torch.argmax(redacted_output, dim=-1)\n",
    "redacted_text = tokenizer.decode(redacted_tokens[0], skip_special_tokens=True)\n",
    "\n",
    "# Get the original text from the PDF file\n",
    "with open(file_path, 'rb') as pdf_file:\n",
    "    original_pdf_text = load_text_from_file(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# # Download and install the spaCy model\n",
    "# !python -m spacy download en_core_web_sm\n",
    "\n",
    "# Load the model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Redacted text saved to: C:/Users/Ashfak/Downloads/non_redacted_text.txt\n"
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "import spacy\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "\n",
    "# Load spaCy NER model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def redact_pii_text(text):\n",
    "    # Process the text with spaCy\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    # Define a set of entity labels to redact\n",
    "    pii_labels = {\"PERSON\", \"GPE\", \"DATE\", \"PHONE\", \"EMAIL\", \"EmailAddress\"}\n",
    "    \n",
    "    # Redact identified PII entities from the text\n",
    "    redacted_text = text\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ in pii_labels:\n",
    "            redacted_text = redacted_text.replace(ent.text, \"[REDACTED]\")\n",
    "    \n",
    "    return redacted_text\n",
    "\n",
    "def process_file(file_path):\n",
    "    if file_path.endswith((\".pdf\")):\n",
    "        with pdfplumber.open(file_path) as pdf:\n",
    "            original_text = \"\"\n",
    "            for page in pdf.pages:\n",
    "                original_text += page.extract_text()\n",
    "        \n",
    "    elif file_path.endswith((\".jpg\", \".jpeg\", \".png\", \".bmp\")):\n",
    "        image = Image.open(file_path)\n",
    "        original_text = pytesseract.image_to_string(image)\n",
    "        \n",
    "    else:\n",
    "        print(\"Unsupported file format\")\n",
    "        return\n",
    "    \n",
    "    redacted_text = redact_pii_text(original_text)\n",
    "    return redacted_text\n",
    "\n",
    "# Example usage\n",
    "file_path = 'D:/Projects/Project Dataset/data hygeine data/pdf/1.pdf'\n",
    "redacted_text = process_file(file_path)\n",
    "\n",
    "# Save the redacted text to a new file\n",
    "output_file_path = 'C:/Users/Ashfak/Downloads/non_redacted_text.txt'\n",
    "with open(output_file_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(redacted_text)\n",
    "\n",
    "print(\"Redacted text saved to:\", output_file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
