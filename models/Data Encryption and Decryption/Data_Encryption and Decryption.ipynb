{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import PyPDF2\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pii_types = ['SSN', 'Social Security Number', 'DOB', 'Date of Birth', 'Name', 'Address', 'Phone Number', 'Phone', 'E-mail', 'EmailAddress', 'Credit Card Number', 'FullNames', 'IDCardNo', 'TelephoneNo', 'Contact', 'PostalAddress']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preparation\n",
    "pdf_directory = 'D:/Projects/Project Dataset/data classification data/confidential_data'\n",
    "pdf_files = glob.glob(os.path.join(pdf_directory, '*.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Ashfak\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Ashfak\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Text Preprocessing\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_data = []\n",
    "labels = []\n",
    "\n",
    "for pdf_file in pdf_files:\n",
    "    with open(pdf_file, 'rb') as pdf:\n",
    "        pdf_reader = PyPDF2.PdfReader(pdf)\n",
    "        text_content = ''\n",
    "        for page in pdf_reader.pages:\n",
    "            text_content += page.extract_text()\n",
    "        \n",
    "        # Tokenize and preprocess text\n",
    "        tokens = word_tokenize(text_content)\n",
    "        tokens = [token.lower() for token in tokens if token.isalnum()]\n",
    "        tokens = [token for token in tokens if token not in stop_words]\n",
    "        \n",
    "        preprocessed_text = ' '.join(tokens)\n",
    "        preprocessed_data.append(preprocessed_text)\n",
    "        \n",
    "        # Determine if the PDF contains PII or not\n",
    "        contains_pii = any(pii_type in text_content for pii_type in pii_types)\n",
    "        labels.append(1 if contains_pii else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed Data for the First PDF:\n",
      "personal informationcurriculum vitae fullnames mike kisasatiwanaswa postaladdress box 85575 80100 mombasa 550926 emailaddress mikewanaswa mlanguages well spoken english swahilipurpose put use latest inventions telecommunication information technology positive impact individuals business enterprises corporate organizations work experience date april 2011 date position fixed data network technician employer ben electronics services ltd mombasa duties survey installation integration maintenance support decommissioning fixed data services using various access technologies wimax fiber microwaves safaricomltd survey installation support ceragon ip20 access technology airtel k survey installation support cambridge p2mp solutions safaricom fiber optics splicing terminations deployment support maintenance design installation technical support structured cabling installation support cctv ip cameras biometrics security controls installation support radwin p2p links ceragon ptmp links installation support telrad wimax bts setup maintenance support e1 installation support systems integration cisco hp huawei platforms mpls p2p vpn internet fixed lte installation safaricom enterprise clients date september 2010 april 2011 position freelance computer technician employer self employed mombasa duties installation software hardware pcs servers printers web design website maintenance repair pcs printers scanners computer accessories design installation support date march 2010 august 2010 position scanning administrator employer interim independent electoral commission duties scanning omr forms extract data voters creation maintenance voters end user training support voter management system mmc mail servers administration network management data recovery repair maintenance scanner printers computers date january 2009 march 2010 position freelance computer e c h n c n duties installation software hardware pcs servers printers repair pcs printers scanners computer accessories support educational background date september 2007 december 2008 institution inoorero university kenya school professional studies nairobicourse diploma computer engineering system administration support grade credit date feb 1997 november 2000 institution bungoma high school bungoma grade kcse mean grade n u date jan 1989 december 1996 institution bungoma deb primary school bungoma grade kcpe 444 700 marks professional trainings date july2018 institution amirancommunications course radwin installer p2p p2mp grade distinction date march2018 institution cambridge broadband networks kenya ltd course vectarstarinstallation grade distinction date jan2018 institution ceragonnetworks course ceragon certified rollout professional grade distinction date june2017 institution e learning course ruckus wireless certified associate support engineer grade distinction date jan 2017 mar 2017 institution iatmombasa course ccna grade distinctiondate july2015 institution viscar industrial capacity ltd course fall arrest height grade distinction note possession clean class bce driving license referees patrick odame regional election coordinator bungoma box 2568 50200 bungoma phone 0720 255 059snyodame k cyrus soi projects manager bens electronics box 726 80100 mombasa phone 0710466547info bensele christine owuor fixed access engineer safaricom p box 66827 00800 nairobi phone 0724 360 530 cowuor kelvin ongoro field engineer safaricom box 66827 00800 nairobi phone 0724619 217kongoro safaricom\n"
     ]
    }
   ],
   "source": [
    "# Print preprocessed data for the first PDF file\n",
    "print(\"Preprocessed Data for the First PDF:\")\n",
    "print(preprocessed_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.89      1.00      0.94         8\n",
      "\n",
      "    accuracy                           0.89         9\n",
      "   macro avg       0.44      0.50      0.47         9\n",
      "weighted avg       0.79      0.89      0.84         9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(preprocessed_data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert text data to TF-IDF features\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Train a Naive Bayes classifier\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = classifier.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the model\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as pii_encryption_model.pkl\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "model_filename = 'pii_encryption_model.pkl'\n",
    "joblib.dump(classifier, model_filename)\n",
    "print(f\"Model saved as {model_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fpdf\n",
      "  Downloading fpdf-1.7.2.tar.gz (39 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: fpdf\n",
      "  Building wheel for fpdf (setup.py): started\n",
      "  Building wheel for fpdf (setup.py): finished with status 'done'\n",
      "  Created wheel for fpdf: filename=fpdf-1.7.2-py2.py3-none-any.whl size=40712 sha256=535a7b9555a0e2359aae86c8c2f983a5d0a81a2328b5dcf443bcff44214489de\n",
      "  Stored in directory: c:\\users\\ashfak\\appdata\\local\\pip\\cache\\wheels\\65\\4f\\66\\bbda9866da446a72e206d6484cd97381cbc7859a7068541c36\n",
      "Successfully built fpdf\n",
      "Installing collected packages: fpdf\n",
      "Successfully installed fpdf-1.7.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 23.2.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install pyDes\n",
    "%pip install fpdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highlighted PII values:\n",
      "<font color=\"red\">[Phone]</font>: 9891423551  , 9650459770  \n",
      "<font color=\"red\">[E-mail]</font>: ardraprasad93@gmail.com  \n",
      "<font color=\"red\">[Name]</font>  : Ardra Prasad  \n",
      "<font color=\"red\">[Date of Birth]</font>  : 23-12-1993  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Ashfak\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Ashfak\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from pyDes import triple_des, PAD_PKCS5, CBC\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.lib import colors\n",
    "from reportlab.platypus import SimpleDocTemplate, Paragraph\n",
    "from reportlab.lib.styles import getSampleStyleSheet\n",
    "import PyPDF2\n",
    "\n",
    "# Load the trained model\n",
    "loaded_classifier = joblib.load('pii_encryption_model.pkl')\n",
    "\n",
    "\n",
    "pdf_path = 'D:/Projects/Project Dataset/data classification data/confidential_data/2.pdf'\n",
    "with open(pdf_path, 'rb') as pdf:\n",
    "    pdf_reader = PyPDF2.PdfReader(pdf)\n",
    "    text_content = ''\n",
    "    for page in pdf_reader.pages:\n",
    "        text_content += page.extract_text()\n",
    "\n",
    "# Preprocess the text content\n",
    "def preprocess_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    # Tokenize and remove stopwords\n",
    "    nltk.download('punkt')\n",
    "    nltk.download('stopwords')\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    \n",
    "    preprocessed_text = ' '.join(tokens)\n",
    "    return preprocessed_text\n",
    "\n",
    "preprocessed_text = preprocess_text(text_content)\n",
    "\n",
    "# Predict if the PDF contains PII data\n",
    "tfidf_text = tfidf_vectorizer.transform([preprocessed_text])\n",
    "prediction = loaded_classifier.predict(tfidf_text)\n",
    "\n",
    "# Encrypt PII using cryptography library if detected\n",
    "if prediction == 1:\n",
    "\n",
    "    key = b\"secretpassword1234567890\"\n",
    "    mode = CBC\n",
    "\n",
    "    pii_mappings = {}\n",
    "\n",
    "    # Regular expressions for PII types\n",
    "    pii_patterns = {\n",
    "        r'\\bSSN\\b': 'SSN',\n",
    "        r'\\bSocial Security Number\\b': 'Social Security Number',\n",
    "        r'\\bDOB\\b': 'DOB',\n",
    "        r'\\bDate of Birth\\b': 'Date of Birth',\n",
    "        r'\\bName\\b': 'Name',\n",
    "        r'\\bPhone Number\\b': 'Phone Number',\n",
    "        r'\\bPhone\\b': 'Phone',\n",
    "        r'\\bE-mail\\b': 'E-mail',\n",
    "        r'\\bEmailAddress\\b': 'EmailAddress',\n",
    "        r'\\bCredit Card Number\\b': 'Credit Card Number',\n",
    "        r'\\bFullNames\\b': 'FullNames',\n",
    "        r'\\bIDCardNo\\b': 'IDCardNo',\n",
    "        r'\\bTelephoneNo\\b': 'TelephoneNo',\n",
    "        r'\\bContact\\b': 'Contact',\n",
    "    }\n",
    "\n",
    "     \n",
    "    encrypted_pii_values = {}\n",
    "\n",
    "    \n",
    "    for pattern, pii_type in pii_patterns.items():\n",
    "        encrypted_value = triple_des(key, mode, padmode=PAD_PKCS5).encrypt(pii_type.encode('utf-8'))\n",
    "        encrypted_pii_values[pii_type] = encrypted_value\n",
    "\n",
    "\n",
    "\n",
    "story = []\n",
    "\n",
    "# styles for normal and highlighted text\n",
    "styles = getSampleStyleSheet()\n",
    "normal_style = styles[\"Normal\"]\n",
    "highlighted_style = normal_style.clone(\"highlighted\")\n",
    "highlighted_style.textColor = colors.red\n",
    "\n",
    "\n",
    "highlighted_values = []\n",
    "\n",
    "for line in text_content.split('\\n'):\n",
    "    for pattern, pii_type in pii_patterns.items():\n",
    "        line = re.sub(pattern, f\"[{pii_type}]\", line)\n",
    "        line = re.sub(rf\"\\[{pii_type}\\]\", f'<font color=\"red\">[{pii_type}]</font>', line)\n",
    "\n",
    "        # Check if a highlighted value is found\n",
    "        if f'<font color=\"red\">[{pii_type}]</font>' in line:\n",
    "            highlighted_values.append(line)\n",
    "\n",
    "\n",
    "doc.build(story)\n",
    "\n",
    "print(\"Highlighted PII values:\")\n",
    "for value in highlighted_values:\n",
    "    print(value)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<font color=\"red\">[Phone]</font>[Phone: b'\\xae\\xf4P\\xc0@\\x9f\\x0e\\x00_\\xea\\xd9\\xc9\\x85z=<3\\x84>5\\x91\\x13\\xdf\\xe9\\xa8\\xf5w3\\xa6\\x06#r']\n",
      "<font color=\"red\">[E-mail]</font>[E-mail: b'8\\xa2&\\x87\\x88\\xad\\xfe\"\\xf3\\xcf\\xa1G\\x02\\xe2V\\x82O\\xafuK\\t/\\xdf\\x86\\x01\\xc0s\\xe8kF\\x0co']\n",
      "<font color=\"red\">[Name]</font>[Name: b'O\\xa5\\xdd\\x0c\\x8f\\xae\\xdc\\xd6\\x95l\\xe7\\x8ea\\xb9\\x9f\\x10\\xc5:\\x15Y\\x9f3\\xae\\xae']\n",
      "<font color=\"red\">[Date of Birth]</font>[Date of Birth: b\"\\x99'\\xd7\\xc7\\xbb\\xad\\xde\\x11\\xafL:\\xfa\\xea&w\\xf5\\xed\\xa3\\xafel\\xd48t\"]\n",
      "All encrypted values saved to C:/Users/Ashfak/Downloads/encrypted_values.txt\n"
     ]
    }
   ],
   "source": [
    "# Encrypt and print the values\n",
    "encrypted_values = {}\n",
    "\n",
    "for value in highlighted_values:\n",
    "    pii_type_start = value.find(\"[\")\n",
    "    pii_type_end = value.find(\"]\") \n",
    "    pii_type = value[pii_type_start+1 : pii_type_end]\n",
    "    \n",
    "    # Find the start of the encryption\n",
    "    encrypted_text_start = value.find(\"</font>\") + len(\"</font>\")\n",
    "    \n",
    "    \n",
    "    text_to_encrypt = value[encrypted_text_start:]\n",
    "    \n",
    "    encrypted_text = triple_des(key, mode, padmode=PAD_PKCS5).encrypt(text_to_encrypt.encode('utf-8'))\n",
    "    encrypted_values[pii_type] = encrypted_text\n",
    "    \n",
    "    # Replace the original text with the encrypted text\n",
    "    encrypted_value = f'[{pii_type}: {encrypted_text}]'\n",
    "    value = value[:encrypted_text_start] + encrypted_value\n",
    "    \n",
    "    print(value)\n",
    "\n",
    "# Save as a file\n",
    "output_txt_path = 'C:/Users/Ashfak/Downloads/encrypted_values.txt'\n",
    "with open(output_txt_path, 'w', encoding='utf-8') as txt_file:\n",
    "    for pii_type, encrypted_text in encrypted_values.items():\n",
    "        txt_file.write(f\"{pii_type}: {encrypted_text}\\n\")\n",
    "\n",
    "print(f\"All encrypted values saved to {output_txt_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All detected PII values saved to C:/Users/Ashfak/Downloads/decrypted_pii_values.txt\n"
     ]
    }
   ],
   "source": [
    "# Detect PII values and save to a file\n",
    "detected_pii_values = []\n",
    "\n",
    "for line in text_content.split('\\n'):\n",
    "    for pattern, pii_type in pii_patterns.items():\n",
    "        if re.search(pattern, line):\n",
    "            detected_pii_values.append(f\"{pii_type}: {line.strip()}\")\n",
    "\n",
    "# Save detected PII values to a file\n",
    "decrypted_pii_output_path = 'C:/Users/Ashfak/Downloads/decrypted_pii_values.txt'\n",
    "with open(decrypted_pii_output_path, 'w', encoding='utf-8') as txt_file:\n",
    "    for detected_pii_value in detected_pii_values:\n",
    "        txt_file.write(f\"{detected_pii_value}\\n\")\n",
    "\n",
    "print(f\"All detected PII values saved to {decrypted_pii_output_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
