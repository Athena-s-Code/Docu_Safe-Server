{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pdfminer\n",
    "from pdfminer.high_level import extract_text\n",
    "from pdfminer.pdfparser import PDFSyntaxError\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preparation\n",
    "pdf_directory = 'D:\\Projects\\Project Dataset\\data hygeine data\\pdf'\n",
    "pdf_files = glob.glob(os.path.join(pdf_directory, '*.pdf'))\n",
    "documents = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting text from D:\\Projects\\Project Dataset\\data hygeine data\\pdf\\1124.pdf: No /Root object! - Is this really a PDF?\n",
      "Error extracting text from D:\\Projects\\Project Dataset\\data hygeine data\\pdf\\1648.pdf: No /Root object! - Is this really a PDF?\n",
      "Error processing D:\\Projects\\Project Dataset\\data hygeine data\\pdf\\3012.pdf: Unexpected EOF\n",
      "Error processing D:\\Projects\\Project Dataset\\data hygeine data\\pdf\\3013.pdf: Unexpected EOF\n"
     ]
    }
   ],
   "source": [
    "for pdf_file in pdf_files:\n",
    "    try:\n",
    "        text = extract_text(pdf_file)\n",
    "        documents.append(text)\n",
    "    except PDFSyntaxError as e:\n",
    "        print(f\"Error extracting text from {pdf_file}: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {pdf_file}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Extraction\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ashfak\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Unsupervised Learning - Automatic Labeling\n",
    "num_clusters = 2  # Number of clusters\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "kmeans.fit(X)\n",
    "labels = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "model = SVC()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99       365\n",
      "           1       0.98      0.99      0.99       288\n",
      "\n",
      "    accuracy                           0.99       653\n",
      "   macro avg       0.99      0.99      0.99       653\n",
      "weighted avg       0.99      0.99      0.99       653\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    try:\n",
    "        with open(pdf_path, 'rb') as pdf_file:\n",
    "            pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
    "            text = \"\"\n",
    "            for page in pdf_reader.pages:\n",
    "                text += page.extract_text()\n",
    "            return text\n",
    "    except Exception as e:\n",
    "        print(f\"PDF Error: {pdf_path} - {e}\")\n",
    "        return \"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: easyocr in c:\\users\\ashfak\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.7.0)\n",
      "Requirement already satisfied: torch in c:\\users\\ashfak\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from easyocr) (2.0.1)\n",
      "Requirement already satisfied: torchvision>=0.5 in c:\\users\\ashfak\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from easyocr) (0.15.2)\n",
      "Requirement already satisfied: opencv-python-headless in c:\\users\\ashfak\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from easyocr) (4.8.0.76)\n",
      "Requirement already satisfied: scipy in c:\\users\\ashfak\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from easyocr) (1.10.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\ashfak\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from easyocr) (1.23.5)\n",
      "Requirement already satisfied: Pillow in c:\\users\\ashfak\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from easyocr) (9.5.0)\n",
      "Requirement already satisfied: scikit-image in c:\\users\\ashfak\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from easyocr) (0.20.0)\n",
      "Requirement already satisfied: python-bidi in c:\\users\\ashfak\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from easyocr) (0.4.2)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\ashfak\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from easyocr) (6.0.1)\n",
      "Requirement already satisfied: Shapely in c:\\users\\ashfak\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from easyocr) (2.0.1)\n",
      "Requirement already satisfied: pyclipper in c:\\users\\ashfak\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from easyocr) (1.3.0.post4)\n",
      "Requirement already satisfied: ninja in c:\\users\\ashfak\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from easyocr) (1.11.1)\n",
      "Requirement already satisfied: requests in c:\\users\\ashfak\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torchvision>=0.5->easyocr) (2.30.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\ashfak\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch->easyocr) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\ashfak\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch->easyocr) (4.7.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\ashfak\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch->easyocr) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\ashfak\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch->easyocr) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ashfak\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch->easyocr) (3.1.2)\n",
      "Requirement already satisfied: six in c:\\users\\ashfak\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-bidi->easyocr) (1.12.0)\n",
      "Requirement already satisfied: imageio>=2.4.1 in c:\\users\\ashfak\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-image->easyocr) (2.28.1)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in c:\\users\\ashfak\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-image->easyocr) (2023.4.12)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in c:\\users\\ashfak\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-image->easyocr) (1.4.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ashfak\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-image->easyocr) (23.1)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in c:\\users\\ashfak\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-image->easyocr) (0.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ashfak\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch->easyocr) (2.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ashfak\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->torchvision>=0.5->easyocr) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ashfak\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->torchvision>=0.5->easyocr) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ashfak\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->torchvision>=0.5->easyocr) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ashfak\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->torchvision>=0.5->easyocr) (2023.5.7)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\ashfak\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy->torch->easyocr) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 23.2.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install easyocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PII keywords detected: Phone, TelephoneNo, EmailAddress, FullNames, IDCardNo, PostalAddress\n",
      "Potential Personally Identifiable Information found.\n",
      "Highlighted PDF file created: C:/Users/Ashfak/Downloads/highlighted.pdf\n"
     ]
    }
   ],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "import re\n",
    "import spacy\n",
    "import fitz\n",
    "import easyocr\n",
    "from fuzzywuzzy import fuzz\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.lib import colors\n",
    "from reportlab.platypus import SimpleDocTemplate, Paragraph\n",
    "from reportlab.lib.styles import getSampleStyleSheet\n",
    "import PyPDF2\n",
    "\n",
    "pii_keywords = [\n",
    "    'SSN', 'Social Security Number',\n",
    "    'DOB', 'Date of Birth',\n",
    "    'Name', 'Address',\n",
    "    'Phone Number', 'Phone', 'TelephoneNo',\n",
    "    'E-mail', 'EmailAddress',\n",
    "    'Credit Card Number',\n",
    "    'FullNames', 'IDCardNo',\n",
    "    'Contact', 'PostalAddress'\n",
    "]\n",
    "\n",
    "def check_for_pii(text):\n",
    "    found_keywords = []\n",
    "    for keyword in pii_keywords:\n",
    "        pattern = re.compile(r'\\b{}\\b'.format(re.escape(keyword)), re.IGNORECASE)\n",
    "        if pattern.search(text):\n",
    "            found_keywords.append(keyword)\n",
    "    return found_keywords\n",
    "\n",
    "# Initialize the easyocr reader\n",
    "reader = easyocr.Reader(lang_list=['en'])\n",
    "\n",
    "def extract_text_from_image(image_path):\n",
    "    result = reader.readtext(image_path)\n",
    "    text = ' '.join(result[1] for result in result)\n",
    "    return text\n",
    "\n",
    "# Load the English language model for spaCy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# File path\n",
    "file_path = 'D:/Projects/Project Dataset/data classification data/confidential_data/1.pdf'  # Update with your file path\n",
    "\n",
    "if file_path.lower().endswith('.pdf'):\n",
    "    # PDF handling logic\n",
    "    with open(file_path, 'rb') as pdf:\n",
    "        pdf_reader = PyPDF2.PdfReader(pdf)\n",
    "        text_content = ''\n",
    "        for page in pdf_reader.pages:\n",
    "            text_content += page.extract_text()\n",
    "    if text_content:\n",
    "        pii_detected = check_for_pii(text_content)\n",
    "        if pii_detected:\n",
    "            print(\"PII keywords detected:\", ', '.join(pii_detected))\n",
    "            print(\"Potential Personally Identifiable Information found.\")\n",
    "\n",
    "            doc = fitz.open(file_path)\n",
    "            num_pages = len(doc)\n",
    "\n",
    "            for page_num in range(num_pages):\n",
    "                page = doc.load_page(page_num)\n",
    "                page_text = page.get_text()\n",
    "\n",
    "                # Search for PII data using fuzzy matching\n",
    "                for keyword in pii_detected:\n",
    "                    matches = re.finditer(rf\"\\b{re.escape(keyword)}\\b\", page_text, flags=re.IGNORECASE)\n",
    "                    for match in matches:\n",
    "                        start_pos = match.start()\n",
    "                        end_pos = match.end()\n",
    "                        text_slice = page_text[start_pos:end_pos]\n",
    "\n",
    "                        match_score = fuzz.partial_ratio(text_slice.lower(), keyword.lower())\n",
    "\n",
    "                        if match_score >= 80:\n",
    "                            instances = page.search_for(text_slice)\n",
    "                            for instance in instances:\n",
    "                                highlight = page.add_rect_annot(instance)\n",
    "                                highlight.set_colors({\"fill\": (1, 0, 1)})\n",
    "\n",
    "            # Save the modified PDF file\n",
    "            output_file = 'C:/Users/Ashfak/Downloads/highlighted.pdf'\n",
    "            doc.save(output_file)\n",
    "            doc.close()\n",
    "\n",
    "            print(\"Highlighted PDF file created:\", output_file)\n",
    "        else:\n",
    "            print(\"No PII keywords detected.\")\n",
    "    else:\n",
    "        print(\"Error: Unable to extract text from the PDF.\")\n",
    "\n",
    "elif file_path.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp')):\n",
    "    # Image handling logic\n",
    "    extracted_text = extract_text_from_image(file_path)\n",
    "    if extracted_text:\n",
    "        pii_detected = check_for_pii(extracted_text)\n",
    "        if pii_detected:\n",
    "            print(\"PII keywords detected:\", ', '.join(pii_detected))\n",
    "            print(\"Potential Personally Identifiable Information found.\")\n",
    "\n",
    "            # Create a PDF document\n",
    "            output_pdf_path = 'C:/Users/Ashfak/Downloads/highlighted_text.pdf'\n",
    "            doc = SimpleDocTemplate(output_pdf_path, pagesize=letter)\n",
    "            styles = getSampleStyleSheet()\n",
    "\n",
    "            # Create a list of paragraphs with highlighted PII data\n",
    "            paragraphs = []\n",
    "            for keyword in pii_detected:\n",
    "                modified_text = re.sub(rf'\\b{re.escape(keyword)}\\b', f'<font color=\"red\">[{keyword}]</font>', extracted_text, flags=re.IGNORECASE)\n",
    "                paragraph = Paragraph(modified_text, style=styles[\"Normal\"])\n",
    "                paragraphs.append(paragraph)\n",
    "\n",
    "            doc.build(paragraphs)\n",
    "\n",
    "            print(\"Modified PDF file created:\", output_pdf_path)\n",
    "        else:\n",
    "            print(\"No PII keywords detected in the image.\")\n",
    "    else:\n",
    "        print(\"Error: Unable to extract text from the image.\")\n",
    "else:\n",
    "    print(\"Unsupported file format.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.2\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
